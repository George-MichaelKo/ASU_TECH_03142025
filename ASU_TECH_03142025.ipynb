{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBZIWAd5gCev",
        "outputId": "8f309258-8439-4008-c3b4-e5514154579f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['Previous_Purchases' 'Frequency_of_Purchases' 'Time_of_Day'\n",
            " 'Browsing_History' 'Sentiment_Analysis' 'Device_Engagement_Level']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0\n",
            "Confusion Matrix:\n",
            " [[0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]]\n",
            "Prediction for user: Auto Care\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['Previous_Purchases' 'Frequency_of_Purchases' 'Time_of_Day'\n",
            " 'Browsing_History' 'Sentiment_Analysis' 'Device_Engagement_Level']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['Previous_Purchases' 'Frequency_of_Purchases' 'Time_of_Day'\n",
            " 'Browsing_History' 'Sentiment_Analysis' 'Device_Engagement_Level']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('newDataset.csv')\n",
        "\n",
        "# Ensure the target variable (Preferred_Product_Category) is a string\n",
        "data['Preferred_Product_Category'] = data['Preferred_Product_Category'].astype(str)\n",
        "\n",
        "# Set the target variable (we're assuming 'Preferred_Product_Category' is the label for product category preference)\n",
        "X = data.drop(columns=['Customer_ID', 'Preferred_Product_Category'])  # Drop non-feature columns\n",
        "y = data['Preferred_Product_Category']\n",
        "\n",
        "# Define categorical and numerical columns\n",
        "categorical_cols = ['Gender', 'Location', 'Preferred_Payment_Method', 'Device_Type', 'Weather',\n",
        "                   'Brand_Affinities', 'Survey_Responses']\n",
        "numerical_cols = ['Age', 'Previous_Purchases', 'Frequency_of_Purchases', 'Time_of_Day', 'Browsing_History',\n",
        "                  'Sentiment_Analysis', 'Device_Engagement_Level']\n",
        "\n",
        "# Ensure no strings are passed to the scaler\n",
        "X[numerical_cols] = X[numerical_cols].apply(pd.to_numeric, errors='coerce')  # Convert to numeric if possible\n",
        "\n",
        "# Create a column transformer with imputers\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='mean')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numerical_cols),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),  # Fill missing categorical values with the most frequent\n",
        "            ('encoder', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
        "        ]), categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Create a pipeline that combines the preprocessor and the classifier\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure that y_train and y_test are string-encoded\n",
        "y_train = y_train.astype(str)\n",
        "y_test = y_test.astype(str)\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = pipeline.predict(X_test)\n",
        "y_pred = y_pred.astype(str)\n",
        "\n",
        "# Evaluate the model\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, y_pred)}\")\n",
        "\n",
        "# Now to make product category recommendations, we use the trained model to predict user preferences\n",
        "# Ensure 'sample_user' matches the column names and data types\n",
        "sample_user = pd.DataFrame({\n",
        "    'Age': [20],\n",
        "    'Gender': ['Male'],\n",
        "    'Location': ['San Francisco'],\n",
        "    'Previous_Purchases': [10],\n",
        "    'Preferred_Payment_Method': ['Credit Card'],\n",
        "    'Frequency_of_Purchases': [4],\n",
        "    'Time_of_Day': [13],  # Time in hours (e.g., 3:00 PM)\n",
        "    'Device_Type': ['Mobile'],\n",
        "    'Browsing_History': [13],\n",
        "    'Weather': ['Windy'],\n",
        "    'Hobbies/Interests': ['Technology'],  # Include all columns expected\n",
        "    'Sentiment_Analysis': [0.2],  # Positive sentiment\n",
        "    'Brand_Affinities': ['Rolex'],\n",
        "    'Survey_Responses': ['Cosmetic'],\n",
        "    'Device_Engagement_Level': [4]  # Make sure this column exists and has a value\n",
        "})\n",
        "\n",
        "# Ensure all columns in sample_user exist in the training data\n",
        "sample_user = sample_user[categorical_cols + numerical_cols]\n",
        "\n",
        "# Predict the product category preference for the sample user\n",
        "user_prediction = pipeline.predict(sample_user)\n",
        "print(f\"Prediction for user: {user_prediction[0]}\")\n"
      ]
    }
  ]
}